{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02773c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: imports & activation helpers\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "def sigmoid(x: float) -> float:\n",
    "    \"\"\"Sigmoid activation function.\"\"\"\n",
    "    return 1.0 / (1.0 + math.exp(-x))\n",
    "\n",
    "def dsigmoid_from_output(y: float) -> float:\n",
    "    \"\"\"\n",
    "    Derivative of sigmoid, expressed in terms of its output y.\n",
    "    If y = sigmoid(x), then d/dx sigmoid(x) = y * (1 - y).\n",
    "    \"\"\"\n",
    "    return y * (1.0 - y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a4aa243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: simple feed-forward NN for Morse → letter\n",
    "\n",
    "class SimpleMorseNN:\n",
    "    \"\"\"\n",
    "    Simple 1-hidden-layer neural network with sigmoid activations,\n",
    "    implemented in plain Python.\n",
    "\n",
    "    Architecture:\n",
    "    - input layer: 3 * max_morse_len (one-hot for dot/dash/void per time step)\n",
    "    - hidden layer: configurable size\n",
    "    - output layer: number of classes (letters A–E) with one-hot targets\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size, lr=0.5, seed=0):\n",
    "        self.lr = lr\n",
    "        random.seed(seed)\n",
    "\n",
    "        # weights: W1[j][i] connects input i -> hidden j\n",
    "        self.W1 = [\n",
    "            [(random.random() - 0.5) * 0.2 for _ in range(input_size)]\n",
    "            for _ in range(hidden_size)\n",
    "        ]\n",
    "        self.b1 = [(random.random() - 0.5) * 0.2 for _ in range(hidden_size)]\n",
    "\n",
    "        # weights: W2[k][j] connects hidden j -> output k\n",
    "        self.W2 = [\n",
    "            [(random.random() - 0.5) * 0.2 for _ in range(hidden_size)]\n",
    "            for _ in range(output_size)\n",
    "        ]\n",
    "        self.b2 = [(random.random() - 0.5) * 0.2 for _ in range(output_size)]\n",
    "\n",
    "        # storage for forward pass\n",
    "        self.last_input = None\n",
    "        self.last_h1 = None\n",
    "        self.last_y = None\n",
    "        self.last_z1 = None\n",
    "        self.last_z2 = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        x: input vector (list or tuple of length input_size).\n",
    "        Returns: output activations (list of length output_size).\n",
    "        \"\"\"\n",
    "        # hidden layer\n",
    "        z1 = []\n",
    "        h1 = []\n",
    "        for j in range(len(self.W1)):\n",
    "            s = sum(w * x_i for w, x_i in zip(self.W1[j], x)) + self.b1[j]\n",
    "            z1.append(s)\n",
    "            h1.append(sigmoid(s))\n",
    "\n",
    "        # output layer\n",
    "        z2 = []\n",
    "        y = []\n",
    "        for k in range(len(self.W2)):\n",
    "            s = sum(w * h for w, h in zip(self.W2[k], h1)) + self.b2[k]\n",
    "            z2.append(s)\n",
    "            y.append(sigmoid(s))\n",
    "\n",
    "        # store for backprop\n",
    "        self.last_input = x\n",
    "        self.last_h1 = h1\n",
    "        self.last_y = y\n",
    "        self.last_z1 = z1\n",
    "        self.last_z2 = z2\n",
    "\n",
    "        return y\n",
    "\n",
    "    def backward(self, target):\n",
    "        \"\"\"\n",
    "        Backward pass (one step of backprop + weight update)\n",
    "        using squared error: E = 0.5 * sum_k (y_k - d_k)^2\n",
    "\n",
    "        target: list of desired outputs (one-hot).\n",
    "        Returns: scalar error E for this pattern.\n",
    "        \"\"\"\n",
    "        x = self.last_input\n",
    "        h1 = self.last_h1\n",
    "        y = self.last_y\n",
    "\n",
    "        # --- deltas for output layer ---\n",
    "        delta2 = []\n",
    "        for k in range(len(y)):\n",
    "            error = y[k] - target[k]                 # ∂E/∂y_k\n",
    "            delta = error * dsigmoid_from_output(y[k])  # δ_k^(2)\n",
    "            delta2.append(delta)\n",
    "\n",
    "        # --- deltas for hidden layer ---\n",
    "        delta1 = []\n",
    "        for j in range(len(h1)):\n",
    "            downstream = sum(delta2[k] * self.W2[k][j] for k in range(len(delta2)))\n",
    "            delta = downstream * dsigmoid_from_output(h1[j])  # δ_j^(1)\n",
    "            delta1.append(delta)\n",
    "\n",
    "        # --- update output weights and biases ---\n",
    "        for k in range(len(self.W2)):\n",
    "            for j in range(len(self.W2[k])):\n",
    "                self.W2[k][j] -= self.lr * delta2[k] * h1[j]\n",
    "            self.b2[k] -= self.lr * delta2[k]\n",
    "\n",
    "        # --- update hidden weights and biases ---\n",
    "        for j in range(len(self.W1)):\n",
    "            for i in range(len(self.W1[j])):\n",
    "                self.W1[j][i] -= self.lr * delta1[j] * x[i]\n",
    "            self.b1[j] -= self.lr * delta1[j]\n",
    "\n",
    "        # --- compute error E = 0.5 * sum (y - d)^2 ---\n",
    "        E = 0.5 * sum((y[k] - target[k]) ** 2 for k in range(len(y)))\n",
    "        return E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2a4265c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letters: ['A', 'B', 'C', 'D', 'E']\n",
      "Max Morse length: 4\n",
      "Input vector size: 12\n",
      "Example: 'A' encoded: [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1]\n",
      "Example: target for 'A': [1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Morse symbol encoding & training data\n",
    "\n",
    "# one-hot per symbol:\n",
    "# dot '.', dash '-', void '_' (padding)\n",
    "symbol_vectors = {\n",
    "    '.': [1, 0, 0],  # dot\n",
    "    '-': [0, 1, 0],  # dash\n",
    "    '_': [0, 0, 1],  # void / padding\n",
    "}\n",
    "\n",
    "def encode_morse(seq: str, max_len: int):\n",
    "    \"\"\"\n",
    "    Encode a Morse string into a flat vector of length max_len * 3.\n",
    "    seq: string like \".-\" (no padding symbols inside this string)\n",
    "    max_len: maximum Morse length over all symbols (here: 4)\n",
    "    \"\"\"\n",
    "    vec = []\n",
    "    # actual symbols\n",
    "    for c in seq:\n",
    "        vec.extend(symbol_vectors[c])\n",
    "    # pad with void symbols\n",
    "    for _ in range(max_len - len(seq)):\n",
    "        vec.extend(symbol_vectors['_'])\n",
    "    return vec\n",
    "\n",
    "# Morse definitions for letters A–E\n",
    "morse_dict = {\n",
    "    'A': '.-',\n",
    "    'B': '-...',\n",
    "    'C': '-.-.',\n",
    "    'D': '-..',\n",
    "    'E': '.',\n",
    "}\n",
    "\n",
    "# determine max length from the codes we use\n",
    "max_len = max(len(code) for code in morse_dict.values())\n",
    "input_size = max_len * 3\n",
    "\n",
    "# alphabet / class list\n",
    "letters = list(morse_dict.keys())\n",
    "\n",
    "# build training data\n",
    "X_train = [encode_morse(morse_dict[ch], max_len) for ch in letters]\n",
    "\n",
    "Y_train = []\n",
    "for ch in letters:\n",
    "    vec = [0] * len(letters)\n",
    "    vec[letters.index(ch)] = 1  # one-hot target\n",
    "    Y_train.append(vec)\n",
    "\n",
    "print(\"Letters:\", letters)\n",
    "print(\"Max Morse length:\", max_len)\n",
    "print(\"Input vector size:\", input_size)\n",
    "print(\"Example: 'A' encoded:\", X_train[0])\n",
    "print(\"Example: target for 'A':\", Y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "203e7010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0 | total error = 2.907471\n",
      "Epoch  200 | total error = 0.495248\n",
      "Epoch  400 | total error = 0.051464\n",
      "Epoch  600 | total error = 0.023627\n",
      "Epoch  800 | total error = 0.015004\n",
      "Epoch 1000 | total error = 0.010884\n",
      "Epoch 1200 | total error = 0.008494\n",
      "Epoch 1400 | total error = 0.006941\n",
      "Epoch 1600 | total error = 0.005855\n",
      "Epoch 1800 | total error = 0.005055\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: training loop\n",
    "\n",
    "hidden_size = 8       # number of hidden neurons\n",
    "output_size = len(letters)\n",
    "learning_rate = 0.5\n",
    "epochs = 2000\n",
    "\n",
    "nn = SimpleMorseNN(input_size, hidden_size, output_size,\n",
    "                   lr=learning_rate, seed=0)\n",
    "\n",
    "errors_per_epoch = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_error = 0.0\n",
    "    # one epoch = loop over all training patterns once\n",
    "    for x, y in zip(X_train, Y_train):\n",
    "        nn.forward(x)                # forward pass\n",
    "        total_error += nn.backward(y)  # backward pass + weight update\n",
    "    errors_per_epoch.append(total_error)\n",
    "\n",
    "    if epoch % 200 == 0:\n",
    "        print(f\"Epoch {epoch:4d} | total error = {total_error:.6f}\")\n",
    "\n",
    "print(\"Training finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d10dba22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Morse .-    | target A  | predicted A  | outputs ['0.972', '0.002', '0.001', '0.012', '0.018']\n",
      "Morse -...  | target B  | predicted B  | outputs ['0.016', '0.972', '0.024', '0.022', '0.000']\n",
      "Morse -.-.  | target C  | predicted C  | outputs ['0.006', '0.020', '0.972', '0.000', '0.016']\n",
      "Morse -..   | target D  | predicted D  | outputs ['0.012', '0.024', '0.001', '0.969', '0.013']\n",
      "Morse .     | target E  | predicted E  | outputs ['0.024', '0.000', '0.022', '0.021', '0.973']\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: test predictions on the training letters (A–E)\n",
    "\n",
    "def predict_letter(morse_seq: str):\n",
    "    \"\"\"\n",
    "    Feed a Morse sequence to the trained network and return:\n",
    "    - predicted letter\n",
    "    - raw output activations\n",
    "    \"\"\"\n",
    "    x = encode_morse(morse_seq, max_len)\n",
    "    y = nn.forward(x)\n",
    "    # argmax over outputs\n",
    "    k = max(range(len(y)), key=lambda i: y[i])\n",
    "    return letters[k], y\n",
    "\n",
    "for ch, seq in morse_dict.items():\n",
    "    pred, y = predict_letter(seq)\n",
    "    y_str = [f\"{v:.3f}\" for v in y]\n",
    "    print(f\"Morse {seq:4s}  | target {ch}  | predicted {pred}  | outputs {y_str}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18953295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment 1: A (.-)  → predicted: A\n",
      "Experiment 2: '-..' (truncated B) → predicted: D outputs: ['0.012', '0.024', '0.001', '0.969', '0.013']\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 (optional): some experiments\n",
    "\n",
    "# Example: feed a padded version of 'A' that is already padded (no change)\n",
    "pred, y = predict_letter(\".-\")\n",
    "print(\"\\nExperiment 1: A (.-)  → predicted:\", pred)\n",
    "\n",
    "# Example: feed B with one missing dot (should likely misclassify)\n",
    "try_seq = '-..'  # true B is '-...'\n",
    "pred, y = predict_letter(try_seq)\n",
    "print(\"Experiment 2: '-..' (truncated B) → predicted:\", pred, \"outputs:\", [f\"{v:.3f}\" for v in y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70773d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "# ----- activation and derivative (sigmoid) -----\n",
    "\n",
    "def sigmoid(x: float) -> float:\n",
    "    \"\"\"Sigmoid activation: squashes any real value into (0,1).\"\"\"\n",
    "    return 1.0 / (1.0 + math.exp(-x))\n",
    "\n",
    "def dsigmoid_from_output(y: float) -> float:\n",
    "    \"\"\"\n",
    "    Derivative of sigmoid using its output.\n",
    "    If y = sigmoid(x), then derivative w.r.t x is y * (1 - y).\n",
    "    \"\"\"\n",
    "    return y * (1.0 - y)\n",
    "\n",
    "\n",
    "# ----- neural network with backpropagation -----\n",
    "\n",
    "class SimpleMorseNN:\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int,\n",
    "                 lr: float = 0.5, seed: int = 0):\n",
    "        self.lr = lr\n",
    "        random.seed(seed)\n",
    "\n",
    "        # weights input -> hidden: W1[j][i]\n",
    "        self.W1 = [\n",
    "            [(random.random() - 0.5) * 0.2 for _ in range(input_size)]\n",
    "            for _ in range(hidden_size)\n",
    "        ]\n",
    "        self.b1 = [(random.random() - 0.5) * 0.2 for _ in range(hidden_size)]\n",
    "\n",
    "        # weights hidden -> output: W2[k][j]\n",
    "        self.W2 = [\n",
    "            [(random.random() - 0.5) * 0.2 for _ in range(hidden_size)]\n",
    "            for _ in range(output_size)\n",
    "        ]\n",
    "        self.b2 = [(random.random() - 0.5) * 0.2 for _ in range(output_size)]\n",
    "\n",
    "        # placeholders to remember last forward pass\n",
    "        self.last_input = None\n",
    "        self.last_hidden = None\n",
    "        self.last_output = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass: compute hidden activations and outputs for input x.\n",
    "        Stores values so backward() can reuse them.\n",
    "        \"\"\"\n",
    "        # hidden layer\n",
    "        h = []\n",
    "        for j in range(len(self.W1)):\n",
    "            s = sum(w * x_i for w, x_i in zip(self.W1[j], x)) + self.b1[j]\n",
    "            h.append(sigmoid(s))\n",
    "\n",
    "        # output layer\n",
    "        y = []\n",
    "        for k in range(len(self.W2)):\n",
    "            s = sum(w * h_j for w, h_j in zip(self.W2[k], h)) + self.b2[k]\n",
    "            y.append(sigmoid(s))\n",
    "\n",
    "        # store for backprop\n",
    "        self.last_input = x\n",
    "        self.last_hidden = h\n",
    "        self.last_output = y\n",
    "\n",
    "        return y\n",
    "\n",
    "    def backward(self, target):\n",
    "        \"\"\"\n",
    "        Backward pass (backpropagation):\n",
    "        - uses last forward pass\n",
    "        - updates weights and biases\n",
    "        - returns error for this sample\n",
    "        \"\"\"\n",
    "        x = self.last_input\n",
    "        h = self.last_hidden\n",
    "        y = self.last_output\n",
    "\n",
    "        # ---- 1) Output layer error signals ----\n",
    "        delta_out = []\n",
    "        for k in range(len(y)):\n",
    "            # difference between actual and desired\n",
    "            error_k = y[k] - target[k]\n",
    "            # scale by how sensitive sigmoid is at this point\n",
    "            delta_k = error_k * dsigmoid_from_output(y[k])\n",
    "            delta_out.append(delta_k)\n",
    "\n",
    "        # ---- 2) Hidden layer error signals ----\n",
    "        delta_hid = []\n",
    "        for j in range(len(h)):\n",
    "            # sum of contributions from all output neurons that depend on this hidden neuron\n",
    "            downstream = sum(delta_out[k] * self.W2[k][j] for k in range(len(delta_out)))\n",
    "            delta_j = downstream * dsigmoid_from_output(h[j])\n",
    "            delta_hid.append(delta_j)\n",
    "\n",
    "        # ---- 3) Update output weights and biases ----\n",
    "        for k in range(len(self.W2)):\n",
    "            for j in range(len(self.W2[k])):\n",
    "                # move weight in direction that reduces error\n",
    "                self.W2[k][j] -= self.lr * delta_out[k] * h[j]\n",
    "            # update bias (acts like a weight with constant input 1)\n",
    "            self.b2[k] -= self.lr * delta_out[k]\n",
    "\n",
    "        # ---- 4) Update hidden weights and biases ----\n",
    "        for j in range(len(self.W1)):\n",
    "            for i in range(len(self.W1[j])):\n",
    "                self.W1[j][i] -= self.lr * delta_hid[j] * x[i]\n",
    "            self.b1[j] -= self.lr * delta_hid[j]\n",
    "\n",
    "        # ---- 5) Compute overall error for this sample ----\n",
    "        E = 0.5 * sum((y[k] - target[k])**2 for k in range(len(y)))\n",
    "        return E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c75894c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: [0.46585223785796287, 0.492556174674926, 0.49870074803411124, 0.4889622334122144, 0.4964410618473407]\n",
      "Error: 0.6310828233465503\n"
     ]
    }
   ],
   "source": [
    "nn = SimpleMorseNN(input_size=12, hidden_size=8, output_size=5, lr=0.5)\n",
    "\n",
    "x_dummy = [0.0] * 12\n",
    "y_dummy = nn.forward(x_dummy)\n",
    "E_dummy = nn.backward([1, 0, 0, 0, 0])\n",
    "\n",
    "print(\"Output:\", y_dummy)\n",
    "print(\"Error:\", E_dummy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0abe1dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letters: ['A', 'B', 'C', 'D', 'E']\n",
      "Max Morse length: 4\n",
      "Input size: 12\n",
      "Example 'A' encoded: [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1]\n",
      "Target for 'A': [1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# --- Symbol encoding (dot, dash, void) ---\n",
    "\n",
    "symbol_vectors = {\n",
    "    '.': [1, 0, 0],  # dot\n",
    "    '-': [0, 1, 0],  # dash\n",
    "    '_': [0, 0, 1],  # void / padding\n",
    "}\n",
    "\n",
    "def encode_morse(seq: str, max_len: int):\n",
    "    \"\"\"\n",
    "    Encode a Morse string into a flat vector of length max_len * 3.\n",
    "    Pads with '_' (void) on the right.\n",
    "    \"\"\"\n",
    "    vec = []\n",
    "    # actual symbols\n",
    "    for c in seq:\n",
    "        vec.extend(symbol_vectors[c])\n",
    "    # pad to max_len\n",
    "    for _ in range(max_len - len(seq)):\n",
    "        vec.extend(symbol_vectors['_'])\n",
    "    return vec\n",
    "\n",
    "# Morse codes for A–E\n",
    "morse_dict = {\n",
    "    'A': '.-',\n",
    "    'B': '-...',\n",
    "    'C': '-.-.',\n",
    "    'D': '-..',\n",
    "    'E': '.',\n",
    "}\n",
    "\n",
    "# figure out max length and input size\n",
    "max_len = max(len(code) for code in morse_dict.values())\n",
    "input_size = max_len * 3\n",
    "\n",
    "# list of classes in order\n",
    "letters = list(morse_dict.keys())\n",
    "\n",
    "# build X (inputs) and Y (one-hot targets)\n",
    "X_train = [encode_morse(morse_dict[ch], max_len) for ch in letters]\n",
    "\n",
    "Y_train = []\n",
    "for ch in letters:\n",
    "    target = [0] * len(letters)\n",
    "    target[letters.index(ch)] = 1  # one-hot\n",
    "    Y_train.append(target)\n",
    "\n",
    "print(\"Letters:\", letters)\n",
    "print(\"Max Morse length:\", max_len)\n",
    "print(\"Input size:\", input_size)\n",
    "print(\"Example 'A' encoded:\", X_train[0])\n",
    "print(\"Target for 'A':\", Y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b94fd585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0 | total error = 2.907471\n",
      "Epoch  200 | total error = 0.495248\n",
      "Epoch  400 | total error = 0.051464\n",
      "Epoch  600 | total error = 0.023627\n",
      "Epoch  800 | total error = 0.015004\n",
      "Epoch 1000 | total error = 0.010884\n",
      "Epoch 1200 | total error = 0.008494\n",
      "Epoch 1400 | total error = 0.006941\n",
      "Epoch 1600 | total error = 0.005855\n",
      "Epoch 1800 | total error = 0.005055\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "# --- Training the network ---\n",
    "\n",
    "hidden_size = 8\n",
    "output_size = len(letters)\n",
    "learning_rate = 0.5\n",
    "epochs = 2000\n",
    "\n",
    "nn = SimpleMorseNN(input_size, hidden_size, output_size,\n",
    "                   lr=learning_rate, seed=0)\n",
    "\n",
    "errors_per_epoch = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_error = 0.0\n",
    "    for x, y in zip(X_train, Y_train):\n",
    "        nn.forward(x)\n",
    "        total_error += nn.backward(y)\n",
    "    errors_per_epoch.append(total_error)\n",
    "\n",
    "    if epoch % 200 == 0:\n",
    "        print(f\"Epoch {epoch:4d} | total error = {total_error:.6f}\")\n",
    "\n",
    "print(\"Training finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6068091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Testing: predict letters from Morse sequences ---\n",
    "\n",
    "def predict_letter(morse_seq: str):\n",
    "    x = encode_morse(morse_seq, max_len)\n",
    "    y = nn.forward(x)\n",
    "    # argmax over outputs\n",
    "    k = max(range(len(y)), key=lambda i: y[i])\n",
    "    return letters[k], y\n",
    "\n",
    "for ch, seq in morse_dict.items():\n",
    "    pred, y = predict_letter(seq)\n",
    "    y_str = [f\"{v:.3f}\" for v in y]\n",
    "    print(f\"Morse {seq:4s} | target {ch} | predicted {pred} | outputs {y_str}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
